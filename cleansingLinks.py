# Copyright 2018 Cerebro Scholar
# generated by JE KIM
"""
cleasning links. (1.re-assign reverse-ordered links 2.drop duplications)

columns : 
    ['p_id_is_cited', 'by_p_id']

use :
    links_clean = cleansing_links(papers_clean, links)
"""
from printUtils import *
import numpy as np

def cleansing_links(dataset, links) :
    print(blue('\n=> Cleansing links..'))
    name = {'a' : 'p_id_is_cited', 'b' : 'by_p_id'}
    
    # Check wrong assigned links by pulished year checking
    d = dataset.set_index('p_id')
    a = links[name['a']].apply(lambda x: d.loc[x].pub_year)
    b = links[name['b']].apply(lambda x: d.loc[x].pub_year)
    print(yellow('There are {:,} wrong assigned links.(reverse-ordered)'.format(sum(a>b))))
    
    # Now Swapping wrong ordered links.
    print(yellow('Now Swapping wrong ordered links.'))
    cereb_links = links.copy()
    cereb_links[name['a']] = np.where(a>b, links[name['b']], links[name['a']])
    cereb_links[name['b']] = np.where(a>b, links[name['a']], links[name['b']])

    # Checking
    a = cereb_links.p_id_is_cited.apply(lambda x: d.loc[x].pub_year)
    b = cereb_links.by_p_id.apply(lambda x: d.loc[x].pub_year)
    print(yellow('Now, There are {:,} wrong links.'.format(sum(a>b))))
    
    # Drop duplicated links
    before = len(cereb_links)
    cereb_links.drop_duplicates(['p_id_is_cited', 'by_p_id'], inplace=True)
    print(yellow('Drop duplicated links. {:,} -> {:,} links'.format(before, len(cereb_links))))

    print(blue('Done.'))
    return cereb_links
                                                